{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqufrL0vwDod"
      },
      "source": [
        "# LLAMA3 Fine-tuning for text classification using QLORA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1719950917608
        },
        "id": "QzSvk9-psdeH"
      },
      "outputs": [],
      "source": [
        "# Install Pytorch\n",
        "#%pip install \"torch==2.2.2\" tensorboard\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "#%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIS0yOVNRHcB"
      },
      "source": [
        "### Big Picture Overview of Parameter Efficient Fine Tuning Methods like LoRA and QLoRA Fine Tuning for Sequence Classification\n",
        "\n",
        "**The Essence of Fine-tuning**\n",
        "- LLMs are pre-trained on vast amounts of data for broad language understanding.\n",
        "- Fine-tuning is crucial for specializing in specific domains or tasks, involving adjustments with smaller, relevant datasets.\n",
        "\n",
        "**Model Fine-tuning with PEFT: Exploring LoRA and QLoRA**\n",
        "- Traditional fine-tuning is resource-intensive; PEFT (Parameter Efficient Fine-tuning) makes the process faster and less demanding.\n",
        "- Focus on two PEFT methods: LoRA and QLoRA.\n",
        "\n",
        "**The Power of PEFT**\n",
        "- PEFT modifies only a subset of the LLM's parameters, enhancing speed and reducing memory demands, making it suitable for less powerful devices.\n",
        "\n",
        "**LoRA: Efficiency through Adapters**\n",
        "- **Low-Rank Adaptation (LoRA):** Injects small trainable adapters into the pre-trained model.\n",
        "- **Equation:** For a weight matrix $W$, LoRA approximates $W = W_0 + BA$, where $W_0$ is the original weight matrix, and $BA$ represents the low-rank modification through trainable matrices $B$ and $A$.\n",
        "- Adapters learn task nuances while keeping the majority of the LLM unchanged, minimizing overhead.\n",
        "\n",
        "**QLoRA: Compression and Speed**\n",
        "- **Quantized LoRA (QLoRA):** Extends LoRA by quantizing the model’s weights, further reducing size and enhancing speed.\n",
        "- **Innovations in QLoRA:**\n",
        "  1. **4-bit Quantization:** Uses a 4-bit data type, NormalFloat (NF4), for optimal weight quantization, drastically reducing memory usage.\n",
        "  2. **Low-Rank Adapters:** Fine-tuned with 16-bit precision to effectively capture task-specific nuances.\n",
        "  3. **Double Quantization:** Reduces quantization constants from 32-bit to 8-bit, saving additional memory without accuracy loss.\n",
        "  4. **Paged Optimizers:** Manages memory efficiently during training, optimizing for large tasks.\n",
        "\n",
        "**Why PEFT Matters**\n",
        "- **Rapid Learning:** Speeds up model adaptation.\n",
        "- **Smaller Footprint:** Eases deployment with reduced model size.\n",
        "- **Edge-Friendly:** Fits better on devices with limited resources, enhancing accessibility.\n",
        "\n",
        "**Conclusion**\n",
        "- PEFT methods like LoRA and QLoRA revolutionize LLM fine-tuning by focusing on efficiency, facilitating faster adaptability, smaller models, and broader device compatibility.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAs9tbj8tiBZ"
      },
      "source": [
        "### Fine-tuning for Text Classification:\n",
        "\n",
        "\n",
        "#### 1. Text Generation with Classification Label as part of text\n",
        "- **Approach**: Train the model to generate text that naturally appends the classification label at the end.\n",
        "- **Input**: \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\"\n",
        "- **Output**: \"Lorem ipsum dolor sit amet, consectetur adipiscing elit 0.25\"\n",
        "\n",
        "\n",
        "#### 2. Sequence Classification Head\n",
        "- **Approach**: Add a sequence classification head (linear layer) on top of the LLaMa Model transformer. \n",
        "- **Input**: Specific sentences (e.g., \"Lorem ipsum dolor sit amet, consectetur adipiscing elit\").\n",
        "- **Output**: Direct classification (e.g., \"0.25\", \"0.50\").\n",
        "- **Training Objective**: Minimize cross-entropy loss between the predicted and the actual sentiment labels.\n",
        "\n",
        "\n",
        "### Peft Configs\n",
        "* Bits and bytes config for quantization\n",
        "* Lora config for lora\n",
        "\n",
        "### Going to use Hugginface Transformers trainer class: Main componenents\n",
        "* Hugging face dataset (for train + eval)\n",
        "* Data collater\n",
        "* Compute Metrics\n",
        "* Class weights since we use custom trainer and also custom weighted loss..\n",
        "* trainingArgs: like # epochs, learning rate, weight decay etc..\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCNt55YNyA3d"
      },
      "source": [
        "### Login to huggingface hub to put your LLama token so we can access Llama 3 7B Param Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N8157Tsw3Vo3"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # defaults to loading from .env file\n",
        "hugginface_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "#hugginface_token= \"hf_V\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_5AVUyey1io"
      },
      "source": [
        "###### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1720052464680
        },
        "id": "h5NPLc7isjdM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-13 09:17:35.122922: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-13 09:17:35.129536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-06-13 09:17:35.137443: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-06-13 09:17:35.139833: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-13 09:17:35.146589: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-06-13 09:17:35.565868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import functools\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import evaluate\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "from datasets import Dataset, DatasetDict\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1720053018867
        },
        "id": "R2o1th0qp4c2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC0ls6RVlzHC"
      },
      "source": [
        "* Add also a numeric 0,1,2,3,4 version of label since we will need it later for fine tuning. We can save it in 'score_category'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1720053021270
        },
        "id": "kHiBd07ikx0N"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>score_ascat</th>\n",
              "      <th>score_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>abatement</td>\n",
              "      <td>abatement of pollution</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7b9652b17b68b7a4</td>\n",
              "      <td>abatement</td>\n",
              "      <td>act of abating</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36d72442aefd8232</td>\n",
              "      <td>abatement</td>\n",
              "      <td>active catalyst</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5296b0c19e1ce60e</td>\n",
              "      <td>abatement</td>\n",
              "      <td>eliminating process</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54c1e3b9184cb5b6</td>\n",
              "      <td>abatement</td>\n",
              "      <td>forest region</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36468</th>\n",
              "      <td>8e1386cbefd7f245</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden article</td>\n",
              "      <td>B44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36469</th>\n",
              "      <td>42d9e032d1cd3242</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden box</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36470</th>\n",
              "      <td>208654ccb9e14fa3</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden handle</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36471</th>\n",
              "      <td>756ec035e694722b</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden material</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36472</th>\n",
              "      <td>8d135da0b55b8c88</td>\n",
              "      <td>wood article</td>\n",
              "      <td>wooden substrate</td>\n",
              "      <td>B44</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36473 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id        anchor                  target context  score  \\\n",
              "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
              "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
              "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
              "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
              "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
              "...                 ...           ...                     ...     ...    ...   \n",
              "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00   \n",
              "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50   \n",
              "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50   \n",
              "36471  756ec035e694722b  wood article         wooden material     B44   0.75   \n",
              "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50   \n",
              "\n",
              "      score_ascat  score_category  \n",
              "0            0.50               2  \n",
              "1            0.75               3  \n",
              "2            0.25               1  \n",
              "3            0.50               2  \n",
              "4            0.00               0  \n",
              "...           ...             ...  \n",
              "36468        1.00               4  \n",
              "36469        0.50               2  \n",
              "36470        0.50               2  \n",
              "36471        0.75               3  \n",
              "36472        0.50               2  \n",
              "\n",
              "[36473 rows x 7 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['score_ascat']=df['score'].astype('category')\n",
        "df['score_category']=df['score_ascat'].cat.codes\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnaLFMhfk1u_"
      },
      "source": [
        "* Suppose you want to decode later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1720053088213
        },
        "id": "r0eMOMiky_8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>36473</td>\n",
              "      <td>36473</td>\n",
              "      <td>36473</td>\n",
              "      <td>36473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>36473</td>\n",
              "      <td>733</td>\n",
              "      <td>29340</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>37d61fd2272659b1</td>\n",
              "      <td>component composite coating</td>\n",
              "      <td>composition</td>\n",
              "      <td>H01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>152</td>\n",
              "      <td>24</td>\n",
              "      <td>2186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id                       anchor       target context\n",
              "count              36473                        36473        36473   36473\n",
              "unique             36473                          733        29340     106\n",
              "top     37d61fd2272659b1  component composite coating  composition     H01\n",
              "freq                   1                          152           24    2186"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['score_ascat'].cat.categories\n",
        "df.describe(include='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1720053115165
        },
        "id": "oZEezWPak0Oh",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1.0}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_map = {code: category for code, category in enumerate(df['score_ascat'].cat.categories)}\n",
        "category_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv3ToinDzIwE"
      },
      "source": [
        "### Convert from Pandas DataFrame to Hugging Face Dataset\n",
        "* Also let's shuffle the training set.\n",
        "* We put the components train,val,test into a DatasetDict so we can access them later with HF trainer.\n",
        "* Later we will add a tokenized dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1720056089938
        },
        "id": "1g5EdzTN21Tq"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "train_size = 0.8 # 80% of data\n",
        "test_size = 0.2 # 20% of data\n",
        "df_train, df_val = train_test_split(pd.read_csv(\"data/train.csv\"), train_size=train_size, test_size=test_size, random_state=42)\n",
        "\n",
        "def generate_features(df):\n",
        "  df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\n",
        "  if 'score' in df.columns:\n",
        "    df['score_ascat']=df['score'].astype('category')\n",
        "    df['score_category']=df['score_ascat'].cat.codes\n",
        "  else:\n",
        "    df['score_category'] = pd.NA\n",
        "\n",
        "generate_features(df_train)\n",
        "generate_features(df_val)\n",
        "\n",
        "\n",
        "# Converting pandas DataFrames into Hugging Face Dataset objects:\n",
        "dataset_train = Dataset.from_pandas(df_train.drop(['score_ascat', 'score'],axis=1).reset_index(drop=True))\n",
        "dataset_val = Dataset.from_pandas(df_val.drop(['score_ascat', 'score'],axis=1).reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1720056885366
        },
        "id": "xREu-St-zeGE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'anchor', 'target', 'context', 'input', 'score_category'],\n",
              "        num_rows: 29178\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['id', 'anchor', 'target', 'context', 'input', 'score_category'],\n",
              "        num_rows: 7295\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine them into a single DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': dataset_train,\n",
        "    'val': dataset_val,\n",
        "})\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6mX_Hfe0hei"
      },
      "source": [
        "* Since our classes are not balanced let's calculate class weights based on inverse value counts\n",
        "* Convert to pytorch tensor since we will need it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1720056899952
        },
        "id": "Z6z0M7tf0g3q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "score_category\n",
              "2    0.337994\n",
              "1    0.315854\n",
              "0    0.204538\n",
              "3    0.109500\n",
              "4    0.032113\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.score_category.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1720057969380
        },
        "id": "e6Nvgfy-zsyM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0953, 0.0617, 0.0577, 0.1781, 0.6072])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_weights=(1/df_train.score_category.value_counts(normalize=True).sort_index()).tolist()\n",
        "class_weights=torch.tensor(class_weights)\n",
        "class_weights=class_weights/class_weights.sum()\n",
        "class_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QolyR2Cd2Bsg"
      },
      "source": [
        "## Load LLama model with 4 bit quantization as specified in bits and bytes and prepare model for peft training\n",
        "\n",
        "### Model Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1720054181900
        },
        "id": "mXkyNcgt2fet"
      },
      "outputs": [],
      "source": [
        "model_name = \"meta-llama/Llama-3.1-8B\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzRyVNmN2jlO"
      },
      "source": [
        "#### Quantization Config (for QLORA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1720054183577
        },
        "id": "BtR7MXs43GJf"
      },
      "outputs": [],
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True, # enable 4-bit quantization\n",
        "    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n",
        "    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n",
        "    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxRLidIwS4Xu"
      },
      "source": [
        "#### Lora Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1720054187625
        },
        "id": "EG950ljoS3RM"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r = 16, # the dimension of the low-rank matrices\n",
        "    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n",
        "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
        "    lora_dropout = 0.05, # dropout probability of the LoRA layers\n",
        "    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n",
        "    task_type = 'SEQ_CLS'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brl04t2KS69t"
      },
      "source": [
        "#### Load model\n",
        "* AutomodelForSequenceClassification\n",
        "* Num Labels is # of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1720057989009
        },
        "id": "pJtZAdKp4WdT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f57d47bf84434e65a6ee3de9f982d1d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f5b8e7380854c27b4b16467f5c9e5e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.1-8B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LlamaForSequenceClassification(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (score): Linear(in_features=4096, out_features=5, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    num_labels=len(category_map)\n",
        ")\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prFT0qY0mVkR"
      },
      "source": [
        "* prepare_model_for_kbit_training() function to preprocess the quantized model for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1720057993981
        },
        "id": "-NcEtG0jmTqO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForSequenceClassification(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (score): Linear(in_features=4096, out_features=5, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25JDWS0Hmb0y"
      },
      "source": [
        "* get_peft_model prepares a model for training with a PEFT method such as LoRA by wrapping the base model and PEFT configuration with get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1720057997545
        },
        "id": "zIXKJgTfmU-H"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForSequenceClassification(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (score): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=4096, out_features=5, bias=False)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=4096, out_features=5, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = get_peft_model(model, lora_config)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j9Ubd2DVAOW"
      },
      "source": [
        "### Load the tokenizer\n",
        "\n",
        "#### Since LLAMA3 pre-training doesn't have EOS token\n",
        "* Set the pad_token_id to eos_token_id\n",
        "* Set pad token ot eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1720054675017
        },
        "id": "DzS5OhVO8Tuo"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akDra1649hcn"
      },
      "source": [
        "#### Update some model configs\n",
        "* Must use .cache = False as below or it crashes from my experience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1720058012627
        },
        "id": "XBFCNrrE9hAR"
      },
      "outputs": [],
      "source": [
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aM2eCK47kf2"
      },
      "source": [
        "# Trainer Components\n",
        "* model\n",
        "* tokenizer\n",
        "* training arguments\n",
        "* train dataset\n",
        "* eval dataset\n",
        "* Data Collater\n",
        "* Compute Metrics\n",
        "* class_weights: In our case since we are using a custom trainer so we can use a weighted loss we will subclass trainer and define the custom loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQCINMPIVgvS"
      },
      "source": [
        "#### Create LLAMA tokenized dataset which will house our train/val parts during the training process but after applying tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1720058030896
        },
        "id": "MJ8t0ZtVVfPv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b6641bf8b8c41ae8bfbdc5fc272724b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/29178 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3441d6062984788b5a13f597da11615",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7295 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_LEN = 512\n",
        "col_to_delete = ['id', 'anchor', 'context', 'target']\n",
        "\n",
        "def llama_preprocessing_function(examples):\n",
        "    return tokenizer(examples['input'], truncation=True, max_length=MAX_LEN)\n",
        "\n",
        "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"score_category\", \"label\")\n",
        "tokenized_datasets.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'TEXT1: G01; TEXT2: antigen immunoassay; ANC1: antigen composition',\n",
              " 'label': tensor(2),\n",
              " 'input_ids': tensor([128000,  12998,     16,     25,    480,   1721,     26,  16139,     17,\n",
              "             25,  83089,   4998,  16711,    395,    352,     26,  86114,     16,\n",
              "             25,  83089,  18528]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFMAsvJFVlMc"
      },
      "source": [
        "## Data Collator\n",
        "A **data collator** prepares batches of data for training or inference in machine learning, ensuring uniform formatting and adherence to model input requirements. This is especially crucial for variable-sized inputs like text sequences.\n",
        "\n",
        "### Functions of Data Collator\n",
        "\n",
        "1. **Padding:** Uniformly pads sequences to the length of the longest sequence using a special token, allowing simultaneous batch processing.\n",
        "2. **Batching:** Groups individual data points into batches for efficient processing.\n",
        "3. **Handling Special Tokens:** Adds necessary special tokens to sequences.\n",
        "4. **Converting to Tensor:** Transforms data into tensors, the required format for machine learning frameworks.\n",
        "\n",
        "### `DataCollatorWithPadding`\n",
        "\n",
        "The `DataCollatorWithPadding` specifically manages padding, using a tokenizer to ensure that all sequences are padded to the same length for consistent model input.\n",
        "\n",
        "- **Syntax:** `collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)`\n",
        "- **Purpose:** Automatically pads text data to the longest sequence in a batch, crucial for models like BERT or GPT.\n",
        "- **Tokenizer:** Uses the provided `tokenizer` for sequence processing, respecting model-specific vocabulary and formatting rules.\n",
        "\n",
        "This collator is commonly used with libraries like Hugging Face's Transformers, facilitating data preprocessing for various NLP models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1720058033937
        },
        "id": "XfpRu7l5Vjx9"
      },
      "outputs": [],
      "source": [
        "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHh8YAiqVu06"
      },
      "source": [
        "# define which metrics to compute for evaluation\n",
        "* We will use balanced accuracy and accuracy for simplicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1720058039266
        },
        "id": "F3fjS8YO4do1"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    try:\n",
        "        # it's a classification task, take the argmax\n",
        "        predictions_processed = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Calculate Pearson correlation\n",
        "        pearson, _ = pearsonr(predictions_processed, labels)\n",
        "\n",
        "        return {'pearson': pearson}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in compute_metrics: {e}\")\n",
        "        return {'pearson': None}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IKaB5d6Wbni"
      },
      "source": [
        "### Define custom trainer with classweights\n",
        "* We will have a custom loss function that deals with the class weights and have class weights as additional argument in constructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1720058045595
        },
        "id": "wc4zAX1iXvDD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = (\n",
        "            torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
        "            if class_weights is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\").long()\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
        "        else:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfFh6JMw8y7E"
      },
      "source": [
        "# define training args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1720058048519
        },
        "id": "5AET29lE9qqw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvzeyu/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = 'sequence_classification',\n",
        "    learning_rate = 1e-4,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    num_train_epochs = 2,\n",
        "    weight_decay = 0.01,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyDI7Wm89-0p"
      },
      "source": [
        "#### Define custom trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1720058051324
        },
        "id": "BGHhP9R09rUR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_535913/1077497925.py:7: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n",
            "/tmp/ipykernel_535913/1077497925.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
          ]
        }
      ],
      "source": [
        "trainer = CustomTrainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_datasets['train'],\n",
        "    eval_dataset = tokenized_datasets['val'],\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = collate_fn,\n",
        "    compute_metrics = compute_metrics,\n",
        "    class_weights=class_weights,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCN4zFN0fRpJ"
      },
      "source": [
        "* https://huggingface.co/docs/transformers/en/training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tIQ3lxk-BLL"
      },
      "source": [
        "### Run trainer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1720083063898
        },
        "id": "qLXOgM0FkaKE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvzeyu/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3648' max='3648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3648/3648 2:25:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.771000</td>\n",
              "      <td>0.711414</td>\n",
              "      <td>0.790840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.597000</td>\n",
              "      <td>0.634859</td>\n",
              "      <td>0.818686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvzeyu/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_result = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSTf1TMf8NpC"
      },
      "source": [
        "#### Let's check the results\n",
        "* I wrapped in a function a convenient way add the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1720086869288
        },
        "id": "uxIXBpIHeWKc"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model, df):\n",
        "\n",
        "\n",
        "  # Convert summaries to a list\n",
        "  sentences = df.input.tolist()\n",
        "\n",
        "  # Define the batch size\n",
        "  batch_size = 32  # You can adjust this based on your system's memory capacity\n",
        "\n",
        "  # Initialize an empty list to store the model outputs\n",
        "  all_outputs = []\n",
        "\n",
        "  # Process the sentences in batches\n",
        "  for i in range(0, len(sentences), batch_size):\n",
        "      # Get the batch of sentences\n",
        "      batch_sentences = sentences[i:i + batch_size]\n",
        "\n",
        "      # Tokenize the batch\n",
        "      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "      # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
        "      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
        "\n",
        "      # Perform inference and store the logits\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**inputs)\n",
        "          all_outputs.append(outputs['logits'])\n",
        "\n",
        "  final_outputs = torch.cat(all_outputs, dim=0)\n",
        "  df['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
        "  df['predictions']=df['predictions'].apply(lambda l:category_map[l])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPokM-op4ZZF"
      },
      "source": [
        "### Analyze performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1720057866926
        },
        "id": "ZJ3eFsPz4Hd9"
      },
      "outputs": [],
      "source": [
        "def get_performance_metrics(df_test):\n",
        "  y_test = df_test.score.round()\n",
        "  y_pred = df_test.predictions.round()\n",
        "  print(f\"comparing test {y_test} and pred {y_pred}\")\n",
        "\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
        "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1720088040819
        },
        "id": "hrPwJ-RSsTXd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "comparing test 33511    0.0\n",
            "18670    0.0\n",
            "18049    0.0\n",
            "31660    1.0\n",
            "15573    0.0\n",
            "        ... \n",
            "5040     0.0\n",
            "33907    1.0\n",
            "9090     0.0\n",
            "25999    0.0\n",
            "22135    0.0\n",
            "Name: score, Length: 7295, dtype: float64 and pred 33511    0.0\n",
            "18670    0.0\n",
            "18049    0.0\n",
            "31660    0.0\n",
            "15573    1.0\n",
            "        ... \n",
            "5040     0.0\n",
            "33907    1.0\n",
            "9090     0.0\n",
            "25999    0.0\n",
            "22135    0.0\n",
            "Name: predictions, Length: 7295, dtype: float64\n",
            "Confusion Matrix:\n",
            "[[5830  414]\n",
            " [ 234  817]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.93      0.95      6244\n",
            "         1.0       0.66      0.78      0.72      1051\n",
            "\n",
            "    accuracy                           0.91      7295\n",
            "   macro avg       0.81      0.86      0.83      7295\n",
            "weighted avg       0.92      0.91      0.91      7295\n",
            "\n",
            "Balanced Accuracy Score: 0.8555256242948511\n",
            "Accuracy Score: 0.9111720356408499\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>input</th>\n",
              "      <th>score_ascat</th>\n",
              "      <th>score_category</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33511</th>\n",
              "      <td>ed1c4e525eb105fe</td>\n",
              "      <td>transmit alarm</td>\n",
              "      <td>display indicator</td>\n",
              "      <td>G08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>TEXT1: G08; TEXT2: display indicator; ANC1: tr...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18670</th>\n",
              "      <td>5386316f318f5221</td>\n",
              "      <td>locking formation</td>\n",
              "      <td>retaining element</td>\n",
              "      <td>B60</td>\n",
              "      <td>0.25</td>\n",
              "      <td>TEXT1: B60; TEXT2: retaining element; ANC1: lo...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18049</th>\n",
              "      <td>1544ca6753fcbddd</td>\n",
              "      <td>lateral power</td>\n",
              "      <td>transducer</td>\n",
              "      <td>H01</td>\n",
              "      <td>0.25</td>\n",
              "      <td>TEXT1: H01; TEXT2: transducer; ANC1: lateral p...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31660</th>\n",
              "      <td>f9d8979b94cec923</td>\n",
              "      <td>spreader body</td>\n",
              "      <td>spreader</td>\n",
              "      <td>A01</td>\n",
              "      <td>0.75</td>\n",
              "      <td>TEXT1: A01; TEXT2: spreader; ANC1: spreader body</td>\n",
              "      <td>0.75</td>\n",
              "      <td>3</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15573</th>\n",
              "      <td>e151ca5ea5cc0f08</td>\n",
              "      <td>high gradient magnetic separators</td>\n",
              "      <td>magnetic filtration</td>\n",
              "      <td>B03</td>\n",
              "      <td>0.50</td>\n",
              "      <td>TEXT1: B03; TEXT2: magnetic filtration; ANC1: ...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5040</th>\n",
              "      <td>f297c5e94dd07e6e</td>\n",
              "      <td>cervical support</td>\n",
              "      <td>gel pack</td>\n",
              "      <td>A47</td>\n",
              "      <td>0.25</td>\n",
              "      <td>TEXT1: A47; TEXT2: gel pack; ANC1: cervical su...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33907</th>\n",
              "      <td>06779da2bf614d00</td>\n",
              "      <td>trommel screen</td>\n",
              "      <td>trommel screen</td>\n",
              "      <td>B03</td>\n",
              "      <td>1.00</td>\n",
              "      <td>TEXT1: B03; TEXT2: trommel screen; ANC1: tromm...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9090</th>\n",
              "      <td>ed6245a94e7e5a77</td>\n",
              "      <td>different conductivity</td>\n",
              "      <td>conductive</td>\n",
              "      <td>H03</td>\n",
              "      <td>0.50</td>\n",
              "      <td>TEXT1: H03; TEXT2: conductive; ANC1: different...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25999</th>\n",
              "      <td>f93d71c0e9af4923</td>\n",
              "      <td>prolog</td>\n",
              "      <td>sliding window</td>\n",
              "      <td>H03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>TEXT1: H03; TEXT2: sliding window; ANC1: prolog</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22135</th>\n",
              "      <td>063e67d59876e127</td>\n",
              "      <td>operator identification information</td>\n",
              "      <td>risk identification</td>\n",
              "      <td>H04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>TEXT1: H04; TEXT2: risk identification; ANC1: ...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7295 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id                               anchor  \\\n",
              "33511  ed1c4e525eb105fe                       transmit alarm   \n",
              "18670  5386316f318f5221                    locking formation   \n",
              "18049  1544ca6753fcbddd                        lateral power   \n",
              "31660  f9d8979b94cec923                        spreader body   \n",
              "15573  e151ca5ea5cc0f08    high gradient magnetic separators   \n",
              "...                 ...                                  ...   \n",
              "5040   f297c5e94dd07e6e                     cervical support   \n",
              "33907  06779da2bf614d00                       trommel screen   \n",
              "9090   ed6245a94e7e5a77               different conductivity   \n",
              "25999  f93d71c0e9af4923                               prolog   \n",
              "22135  063e67d59876e127  operator identification information   \n",
              "\n",
              "                    target context  score  \\\n",
              "33511    display indicator     G08   0.00   \n",
              "18670    retaining element     B60   0.25   \n",
              "18049           transducer     H01   0.25   \n",
              "31660             spreader     A01   0.75   \n",
              "15573  magnetic filtration     B03   0.50   \n",
              "...                    ...     ...    ...   \n",
              "5040              gel pack     A47   0.25   \n",
              "33907       trommel screen     B03   1.00   \n",
              "9090            conductive     H03   0.50   \n",
              "25999       sliding window     H03   0.00   \n",
              "22135  risk identification     H04   0.00   \n",
              "\n",
              "                                                   input score_ascat  \\\n",
              "33511  TEXT1: G08; TEXT2: display indicator; ANC1: tr...        0.00   \n",
              "18670  TEXT1: B60; TEXT2: retaining element; ANC1: lo...        0.25   \n",
              "18049  TEXT1: H01; TEXT2: transducer; ANC1: lateral p...        0.25   \n",
              "31660   TEXT1: A01; TEXT2: spreader; ANC1: spreader body        0.75   \n",
              "15573  TEXT1: B03; TEXT2: magnetic filtration; ANC1: ...        0.50   \n",
              "...                                                  ...         ...   \n",
              "5040   TEXT1: A47; TEXT2: gel pack; ANC1: cervical su...        0.25   \n",
              "33907  TEXT1: B03; TEXT2: trommel screen; ANC1: tromm...        1.00   \n",
              "9090   TEXT1: H03; TEXT2: conductive; ANC1: different...        0.50   \n",
              "25999    TEXT1: H03; TEXT2: sliding window; ANC1: prolog        0.00   \n",
              "22135  TEXT1: H04; TEXT2: risk identification; ANC1: ...        0.00   \n",
              "\n",
              "       score_category  predictions  \n",
              "33511               0         0.50  \n",
              "18670               1         0.25  \n",
              "18049               1         0.25  \n",
              "31660               3         0.50  \n",
              "15573               2         0.75  \n",
              "...               ...          ...  \n",
              "5040                1         0.25  \n",
              "33907               4         1.00  \n",
              "9090                2         0.50  \n",
              "25999               0         0.00  \n",
              "22135               0         0.00  \n",
              "\n",
              "[7295 rows x 9 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "make_predictions(model,df_val)\n",
        "\n",
        "get_performance_metrics(df_val)\n",
        "df_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZTHqTuPir_k"
      },
      "source": [
        "### Saving the model trainer state and model adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1720087097537
        },
        "id": "KnCfi0Z3W567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  total_flos               = 52731780GF\n",
            "  train_loss               =     0.7535\n",
            "  train_runtime            = 2:25:36.35\n",
            "  train_samples            =      29178\n",
            "  train_samples_per_second =       6.68\n",
            "  train_steps_per_second   =      0.418\n"
          ]
        }
      ],
      "source": [
        "metrics = train_result.metrics\n",
        "max_train_samples = len(dataset_train)\n",
        "metrics[\"train_samples\"] = min(max_train_samples, len(dataset_train))\n",
        "trainer.log_metrics(\"train\", metrics)\n",
        "trainer.save_metrics(\"train\", metrics)\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CArcZkf509Xq"
      },
      "source": [
        "#### Saving the adapter model\n",
        "* Note this doesn't save the entire model. It only saves the adapters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1720087105908
        },
        "id": "AyDo4GzKaQTo"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./saved_model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernel_info": {
      "name": "custom_py311"
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
